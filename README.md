# ğŸ¤– AI Interviewer - Multi-Agent Interview Simulation Platform

A realistic AI-powered interview simulation system built with **LangGraph** and **Azure OpenAI**. This project demonstrates multi-agent orchestration where three specialized AI agents (Technical, HR, and Manager) conduct a comprehensive interview, followed by an AI-powered evaluation.

## ğŸŒŸ Features

### Multi-Agent Interview System
- **ğŸ’» Technical Agent (Alex)**: Asks 6 technical questions focusing on coding, system design, and problem-solving
- **ğŸ¤ HR Agent (Olivia)**: Asks 3 questions about cultural fit, soft skills, and teamwork
- **ğŸ‘” Manager Agent (Rahul)**: Asks 2 questions about leadership, strategy, and career vision
- **ğŸ¯ Evaluation Agent**: Provides comprehensive AI-generated feedback with scores, strengths, weaknesses, and suggestions

### Key Capabilities
- **Experience-Level Adaptive**: Questions tailored to Junior, Mid-Level, or Senior positions
- **Resume Upload Support**: Upload PDF, DOCX, or TXT resumes for personalized questions
- **LangGraph Orchestration**: Sophisticated workflow management with state transitions
- **Azure OpenAI Integration**: Leverages Azure OpenAI models for intelligent question generation
- **Context-Aware**: Agents adapt questions based on previous answers, candidate profile, and resume
- **Professional Web UI**: Beautiful Streamlit interface with real-time progress tracking
- **AI-Powered Evaluation**: Intelligent analysis of interview performance across all rounds
- **Comprehensive Logging**: Detailed logging system for debugging and monitoring
- **Modular Architecture**: Clean, maintainable code following industry best practices

## ğŸ“ Project Structure

```
AI_Interviewer/
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml              # Streamlit auto-reload configuration
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py              # Environment variables and configuration
â”‚   â””â”€â”€ logging_config.py        # Logging setup with file and console handlers
â”œâ”€â”€ logs/                        # Application logs (auto-generated, not in git)
â”‚   â””â”€â”€ ai_interviewer_*.log     # Timestamped log files
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_agent.py        # Base agent class with LLM initialization
â”‚   â”‚   â”œâ”€â”€ technical_agent.py   # Alex - Technical interviewer (6 questions)
â”‚   â”‚   â”œâ”€â”€ hr_agent.py          # Olivia - HR interviewer (3 questions)
â”‚   â”‚   â”œâ”€â”€ manager_agent.py     # Rahul - Hiring manager (2 questions)
â”‚   â”‚   â””â”€â”€ evaluation_agent.py  # AI evaluation specialist with scoring
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py             # State management with TypedDict and Pydantic models
â”‚   â”‚   â””â”€â”€ workflow.py          # LangGraph workflow orchestration with routing logic
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ templates.py         # Agent prompts, personalities, and resume context
â”œâ”€â”€ app.py                       # Streamlit web application (Main UI) â­
â”œâ”€â”€ main.py                      # CLI application (Alternative interface)
â”œâ”€â”€ azure_clients.py             # Azure OpenAI client initialization
â”œâ”€â”€ test_agent.py                # Test script for individual agents
â”œâ”€â”€ .env                         # Environment variables (not in git)
â”œâ”€â”€ .gitignore                   # Git ignore patterns
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ STREAMLIT_README.md          # Streamlit-specific documentation
â””â”€â”€ README.md                    # This file
```


```

**Features:**
- ğŸ¨ Professional gradient UI design
- ï¿½ Resume upload with automatic text extraction (PDF, DOCX, TXT)
- ï¿½ğŸ“Š Real-time progress tracking across all interview rounds
- ğŸ¤– AI-powered evaluation with detailed feedback
- ğŸ¯ Automatic scoring (0-100)
- ğŸ’ª Personalized strengths analysis
- ğŸ”§ Constructive areas for improvement
- ğŸ’¡ Actionable suggestions for growth
- ğŸ“‹ Complete interview transcript
- ğŸ”„ Automatic reload on code changes
- ğŸ“ Resume preview before interview starts
- ğŸ¯ Context-aware questions based on uploaded resume



### Interview Flow

1. **Welcome Screen** ğŸ‘‹
   - Enter your name
   - Select job role (Software Engineer, Data Scientist, Product Manager, etc.)
   - Choose experience level (Junior/Mid-Level/Senior)
   - **Upload Resume (Optional)** ğŸ“„
     - Supports PDF, DOCX, and TXT formats
     - Resume content is extracted and used for personalized questions
     - Preview extracted text before starting

2. **Technical Round** ğŸ’» (6 questions)
   - Alex, the Technical Interviewer, asks coding, system design, and problem-solving questions
   - Questions adapt to your experience level and resume content
   - Topics: algorithms, best practices, system architecture, technical skills

3. **HR Round** ğŸ¤ (3 questions)
   - Olivia, the HR Manager, assesses cultural fit and soft skills
   - Focus on teamwork, communication, conflict resolution, and values
   - Questions may reference your resume experience

4. **Managerial Round** ğŸ‘” (2 questions)
   - Rahul, the Hiring Manager, evaluates leadership and strategic thinking
   - Questions about decision-making, career vision, and growth potential
   - Tailored to your experience level and background

5. **AI Evaluation** ğŸ¯
   - Comprehensive analysis of your entire interview performance
   - Detailed score (0-100) with clear breakdown
   - Specific strengths identified across all rounds
   - Constructive areas for improvement with context
   - Actionable suggestions for professional growth
   - Overall hiring recommendation based on performance

### Example Web Interface

Visit the app to experience:
- Beautiful gradient cards for each interview round
- Resume upload section with drag-and-drop support
- File format validation and automatic text extraction
- Resume content preview with character count
- Real-time question counters (e.g., "Question 3/6")
- Progress bar showing overall completion
- Professional results screen with color-coded scores
- Detailed feedback sections with icons and formatting
- Comprehensive logging for debugging and monitoring

## ğŸ—ï¸ Architecture

### LangGraph Workflow

The system uses LangGraph to orchestrate a multi-agent interview process with AI evaluation:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Start    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Technical   â”‚â”€â”€â–º Alex asks 6 technical questions
â”‚   Agent     â”‚    (Coding, system design, algorithms)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HR Agent   â”‚â”€â”€â–º Olivia asks 3 HR questions
â”‚             â”‚    (Cultural fit, soft skills)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Manager    â”‚â”€â”€â–º Rahul asks 2 managerial questions
â”‚   Agent     â”‚    (Leadership, strategy, vision)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Evaluation  â”‚â”€â”€â–º AI analyzes entire interview
â”‚   Agent     â”‚    (Score, strengths, weaknesses, suggestions)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     End     â”‚â”€â”€â–º Display comprehensive results
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Design

Each agent:
- Inherits from `BaseAgent`
- Has a unique personality defined in prompt templates
- Uses Azure OpenAI via centralized client (`azure_clients.py`)
- Maintains context from previous answers
- Adapts questions dynamically based on experience level
- Leverages resume content when available for personalized questions
- Generates natural, conversational questions without numbering
- Logs all question generation and state transitions

## ğŸ› ï¸ Technical Components

### Logging System
- **File Handler**: Writes detailed DEBUG logs to `logs/ai_interviewer_TIMESTAMP.log`
- **Console Handler**: Displays INFO level logs to terminal
- **Module-Level Loggers**: Each module has its own logger for granular tracking
- **HTTP Noise Reduction**: Suppresses verbose logs from httpx, httpcore, openai libraries
- **Automatic Directory Creation**: `logs/` directory created automatically if needed

### Document Processing
- **PDF Support**: PyPDF2 for extracting text from PDF resumes
- **DOCX Support**: python-docx for parsing Word documents
- **TXT Support**: Native text file reading
- **Character Limit**: Resume text limited to first 2000 characters for context injection
- **Error Handling**: Graceful fallback if resume parsing fails

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | Azure OpenAI API key | Required |
| `OPENAI_ENDPOINT` | Azure OpenAI endpoint URL | Required |
| `OPENAI_CHAT_DEPLOYMENT_NAME` | Chat deployment name | Required |
| `OPENAI_EMBED_DEPLOYMENT_NAME` | Embedding deployment name | Optional |
| `API_VERSION` | API version | 2024-02-15-preview |
| `MAX_TECHNICAL_QUESTIONS` | Max technical questions | 6 |
| `MAX_HR_QUESTIONS` | Max HR questions | 3 |
| `MAX_MANAGER_QUESTIONS` | Max manager questions | 2 |
| `TEMPERATURE` | Model temperature | 0.7 |

## ğŸ§ª Testing

Run the test script to verify agent functionality:

```bash
python test_agent.py
```

This will test the Technical Agent's question generation with a mock interview state.



### ğŸ”„ Workflow Improvements

- Proper state management with question count increments
- Routing logic optimized for smooth agent transitions
- Evaluation triggered automatically after final question
- Complete interview transcript in results



### v2.0.0 - Resume Upload & Logging System (November 2025)
- âœ¨ **Resume Upload Feature**: Upload your resume in PDF, DOCX, or TXT format
- ğŸ¤– **AI-Powered Personalization**: Questions now adapt based on resume content
- ğŸ“ **Resume Preview**: See extracted text before starting the interview
- ğŸ” **Comprehensive Logging**: File and console logging for debugging and monitoring
- ğŸ“Š **Enhanced State Management**: Resume text included in interview state
- ğŸ¯ **Smart Context Injection**: Resume content (up to 2000 chars) added to agent prompts
- âš¡ **Improved Error Handling**: Graceful fallback if resume parsing fails
- ğŸ“¦ **New Dependencies**: PyPDF2 and python-docx for document processing

### v1.0.0 - Initial Release
- ğŸ¤– Multi-agent interview system with LangGraph orchestration
- ğŸ’» Technical, HR, and Manager interview rounds
- ğŸ¯ AI-powered evaluation and scoring
- ğŸŒ Professional Streamlit web interface
- ğŸ“Š Real-time progress tracking
- ğŸ¨ Beautiful gradient UI design



## ğŸ‘¤ Author

**Debdoot**
- GitHub: [@debdoot9804](https://github.com/debdoot9804)

## ğŸ™ Acknowledgments

- Built with [LangGraph](https://github.com/langchain-ai/langgraph) for multi-agent orchestration
- Powered by [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)
- Uses [LangChain](https://github.com/langchain-ai/langchain) framework
- UI built with [Streamlit](https://streamlit.io/)
- Colorful terminal output with [Colorama](https://github.com/tartley/colorama)
